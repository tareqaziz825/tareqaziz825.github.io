<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Mohammod Tareq Aziz Justice - Research</title>
    <!-- CSS Links etc. -->
    <link href="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/css/bootstrap.min.css" rel="stylesheet">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.0.0/css/all.min.css">
    <link href="https://fonts.googleapis.com/css2?family=Roboto:wght@300;400;500;700&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="styles.css">
</head>

<body>
    <!-- Final Navigation Bar -->
    <nav class="navbar navbar-expand-lg navbar-light fixed-top">
        <div class="container">
            <a class="navbar-brand" href="index.html">MOHAMMOD TAREQ AZIZ JUSTICE</a>
            <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarNav"
                aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation">
                <span class="navbar-toggler-icon"></span>
            </button>
            <div class="collapse navbar-collapse" id="navbarNav">
                <ul class="navbar-nav ms-auto">
                    <li class="nav-item"><a class="nav-link" href="index.html">About</a></li>
                    <li class="nav-item"><a class="nav-link active" href="project.html">Projects</a></li>
                    <li class="nav-item"><a class="nav-link" href="publications.html">Publications</a></li>
                    <li class="nav-item"><a class="nav-link" href="teaching.html">Teaching</a></li>
                    <li class="nav-item"><a class="nav-link" href="experience.html">Experience</a></li>
                    <li class="nav-item"><a class="nav-link" href="qualifications.html">Credentials</a></li>
                    <li class="nav-item"><a class="nav-link" href="awards.html">Awards</a></li>
                    <li class="nav-item"><a class="nav-link" href="others.html">Others</a></li>
                </ul>
                <button id="theme-toggle" class="btn theme-toggle-btn ms-2">
                    <i class="fas fa-moon"></i>
                </button>
            </div>
        </div>
    </nav>

    <!-- Main Content -->
    <main>
        <section id="research" class="section fade-in">
            <div class="container">

                <!-- Research Interests -->
                <h3 class="text-center mb-4">Research Interests</h3>
                <div class="row mb-5">
                    <div class="col-md-6">
                        <ul class="list-unstyled specializations">
                            <li><i class="fas fa-project-diagram"></i> Multi-Modal Machine Learning</li>
                            <li><i class="fas fa-brain"></i> Deep Learning Architectures</li>
                            <li><i class="fas fa-wave-square"></i> Signal & Image Processing</li>
                            <li><i class="fas fa-microphone-alt"></i> Audio and Speech Processing</li>
                            <li><i class="fas fa-sitemap"></i> Federated Learning</li>
                        </ul>
                    </div>
                    <div class="col-md-6">
                        <ul class="list-unstyled specializations">
                            <li><i class="fas fa-eye"></i> Computer Vision and Medical Imaging</li>
                            <li><i class="fas fa-dna"></i> Bioinformatics</li>
                            <li><i class="fas fa-heartbeat"></i> AI in Healthcare</li>
                            <li><i class="fas fa-landmark"></i> Computational Social Science</li>
                            <li><i class="fas fa-microscope"></i> Explainable AI</li>
                        </ul>
                    </div>
                </div>
                <hr class="my-5">

                <!-- Projects Boxes -->

                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="420img.jpg" class="img-fluid rounded" alt="420 Thesis Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">B.Sc. Thesis (CSE)</span>
                                <h4 class="card-title text-primary">Context-Aware Zero-Shot Anomaly Detection in
                                    Surveillance Using Contrastive and Predictive Spatiotemporal Modeling</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Md. Ashraful Alam, Md
                                    Tanzim Reza</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Deep Learning</span>
                                    <span class="badge rounded-pill bg-primary">Overfitting</span>
                                    <span class="badge rounded-pill bg-primary">Optimization</span>
                                </div>
                                <hr>
                                <p>Designed a Zero-Shot, context-aware video anomaly detection framework that detects
                                    unseen abnormal events without requiring anomaly samples during training, leveraging
                                    spatiotemporal prediction and semantic context.</p>
                                <p>Tech Stack: Python, PyTorch, Hugging Face Transformers, TimeSformer, CLIP, DPC-RNN,
                                    CNN, Contrastive & Zero-Shot Learning, InfoNCE/CPC losses, OpenCV, UCF-Crime
                                    dataset. </p>
                                <p>Proposed a dual-stream architecture combining TimeSformer based spatiotemporal
                                    transformers, DPC-based predictive modeling, and CLIP vision–language alignment to
                                    enable pure zero-shot anomaly detection. </p>
                                <p>The model outperformed multiple state-of-the-art zero-shot and vision-only baselines
                                    while reducing false alarms via scene-aware context conditioning. </p>
                                <div class="mb-3">
                                    <a href="https://arxiv.org/pdf/2508.18463" class="btn btn-outline-primary btn-sm"
                                        target="_blank"><i class="fas fa-external-link-alt me-1"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/Divide2Conquer"
                                        class="btn btn-outline-primary btn-sm" target="_blank"><i
                                            class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="S3FNet_SN1.png" class="img-fluid rounded" alt="S3F-Net Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">M.Sc. Thesis (EEE)</span>
                                <h4 class="card-title text-primary">Medical Image Segmentation & Classification based on
                                    a Dual-Domain Approach of Spatial and Spectral Feature Fusion</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Mohammed Imamul Hassan
                                    Bhuiyan</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Computer Vision</span>
                                    <span class="badge rounded-pill bg-primary me-1">Biomedical Imaging</span>
                                    <span class="badge rounded-pill bg-primary">Representation Learning</span>
                                    <span class="badge rounded-pill bg-primary">Multi-Modal Fusion</span>
                                </div>
                                <hr>
                                <p><strong>Part 1 (S³F-Net):</strong> Proposed S³F-Net, a dual-branch framework that
                                    learns from both spatial (CNN) and spectral (SpectraNet) domains simultaneously,
                                    achieving performance improvements over unimodal baselines & state-of-the-art
                                    competitive accuracy on multiple medical imaging datasets.</p>
                                <div class="mb-3">
                                    <a href="https://arxiv.org/abs/2509.23442" class="btn btn-outline-primary btn-sm"
                                        target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/S3F-Net"
                                        class="btn btn-outline-primary btn-sm" target="_blank"><i
                                            class="fab fa-github me-1"></i> Code</a>
                                </div>
                                <p><strong>Part 2 (Spatio-Spectral Medical Image Segmentation):</strong> Currently
                                    extending the S³F-Net architecture to perform robust and accurate segmentation tasks
                                    on medical images, leveraging its multi-domain feature learning capabilities.</p>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-5">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="BRL_RF.JPG" class="img-fluid rounded" alt="BRL Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">B.Sc. Thesis (EEE)</span>
                                <h4 class="card-title text-primary">Bioradiolocation-Based Multi-Class Sleep Stage
                                    Classification</h4>
                                <p class="text-muted"><strong>Supervisor:</strong> Prof. Dr. Mohammed Imamul Hassan
                                    Bhuiyan</p>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Biomedical Signal Processing</span>
                                    <span class="badge rounded-pill bg-primary">Machine Learning</span>
                                </div>
                                <hr>
                                <p>This undergraduate thesis focused on a non-invasive sleep stage classification method
                                    using bioradiolocation signals. By extensively extracting time & frequency domain
                                    features and employing a Random Forest classifier, the system outperformed
                                    state-of-the-art methods in terms of several metrics. Published at ICECE 2022.</p>
                                <div>
                                    <a href="https://doi.org/10.1109/ICECE57408.2022.10089093"
                                        class="btn btn-outline-primary btn-sm" target="_blank"><i
                                            class="fas fa-external-link-alt me-1"></i> Paper</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Ongoing Research Projects -->
                <h3 class="text-center mb-4">Ongoing Research Projects</h3>
                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="July_Revolution.JPG" class="img-fluid rounded"
                                alt="July Revolution Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">Collaboration with University of Oxford</span>
                                <h4 class="card-title text-primary">Machine Learning & Statistical Modeling Driven
                                    Repression and Mobilization Analysis of Bangladesh's Social Movements</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Computational Social Science</span>
                                    <span class="badge rounded-pill bg-primary">Statistical Modeling</span>
                                    <span class="badge rounded-pill bg-primary">Machine Learning</span>
                                </div>
                                <hr>
                                <p>This project applies ML and statistical modeling to analyze the dynamics of state
                                    repression and citizen mobilization during Bangladesh's recent social movements. One
                                    paper from this work focusing on July Revolution is already under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2510.06264" class="btn btn-outline-primary btn-sm"
                                        target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/July-Revolution-Analysis"
                                        class="btn btn-outline-primary btn-sm" target="_blank"><i
                                            class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-4">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="AudioFuse.png" class="img-fluid rounded" alt="AudioFuse Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">BIOML Lab</span>
                                <h4 class="card-title text-primary">Multi-Modal Fusion of Different Representations of
                                    the Signal for Biomedical Audio Analysis</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Audio and Speech Processing</span>
                                    <span class="badge rounded-pill bg-primary me-1">Deep Learning</span>
                                    <span class="badge rounded-pill bg-primary">Multi-Modal Learning</span>
                                </div>
                                <hr>
                                <p>This project explores fusion of features learned from different representations of
                                    biomedical audio signals, to exploit the complementary strengths of each
                                    representation. We explored different representations including waveforms,
                                    spectrograms, and scalograms for robust diagnostic models, and one paper from this
                                    research is currently under review.</p>
                                <div>
                                    <a href="https://arxiv.org/abs/2509.23454" class="btn btn-outline-primary btn-sm"
                                        target="_blank"><i class="fas fa-external-link-alt me-1"></i> Preprint</a>
                                    <a href="https://github.com/Saiful185/AudioFuse"
                                        class="btn btn-outline-primary btn-sm" target="_blank"><i
                                            class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>
                <div class="card mb-5">
                    <div class="row g-0">
                        <div class="col-md-4 d-flex align-items-center justify-content-center p-3">
                            <img src="AMR.JPG" class="img-fluid rounded" alt="AMR Project Image">
                        </div>
                        <div class="col-md-8">
                            <div class="card-body">
                                <span class="badge bg-primary mb-2">BIOML Lab</span>
                                <h4 class="card-title text-primary">Antimicrobial Resistance (AMR) Prediction from
                                    Genomic Data (SNPs) Leveraging Deep Learning & Explainable AI</h4>
                                <div class="mb-2">
                                    <span class="badge rounded-pill bg-primary me-1">Bioinformatics</span>
                                    <span class="badge rounded-pill bg-primary me-1">Explainable AI</span>
                                    <span class="badge rounded-pill bg-primary me-1">Genomics</span>
                                    <span class="badge rounded-pill bg-primary">Ensemble Learning</span>
                                </div>
                                <hr>
                                <p>This research exploits different perspectives provided by different types of models.
                                    We explored the utility of the sequential information available in SNPs through
                                    sequence-aware models and currently investigating fusion mechanisms to combine them
                                    with "bag-of features" models. We also incorporate Explainable-AI methods to
                                    biologically validate our models, by mapping the SNP positions to the corresponding
                                    genes and investigating their relevance in AMR. One paper from this research has
                                    been accepted at SCA/HPCAsia 2026.</p>
                                <div>
                                    <a href="https://www.biorxiv.org/content/early/2025/09/27/2025.09.27.678993"
                                        class="btn btn-outline-primary btn-sm" target="_blank"><i
                                            class="fas fa-external-link-alt me-1"></i> Paper</a>
                                    <a href="https://github.com/Saiful185/AMR-EnsembleNet"
                                        class="btn btn-outline-primary btn-sm" target="_blank"><i
                                            class="fab fa-github me-1"></i> Code</a>
                                </div>
                            </div>
                        </div>
                    </div>
                </div>

                <!-- Research Experience -->
                <h3 class="text-center mb-4">Research Experience</h3>
                <div class="card mb-3">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Research Assistant</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">February - August 2022</span>
                        </div>
                        <h5 class="mb-3">Center for Computational and Data Sciences (CCDS), IUB</h5>
                        <ul>
                            <li>Investigated ML-based methods of Fetal ECG Separation.</li>
                            <li>Contributed to the Graph Neural Networks (GNN) study group.</li>
                        </ul>
                        <a href="https://ccds.ai/" class="btn btn-outline-primary btn-sm" target="_blank"><i
                                class="fas fa-globe me-1"></i>CCDS Homepage</a>
                        <a href="https://drive.google.com/file/d/1JpWXlJMzJZzlKNcEYj8Ir-0FASWLbAyY/view?usp=sharing"
                            class="btn btn-outline-primary btn-sm ms-2" target="_blank"><i
                                class="fas fa-certificate me-1"></i>Experience Certificate</a>
                    </div>
                </div>
                <div class="card mb-5">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Co-founder & Researcher</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">2025 - Present</span>
                        </div>
                        <h5 class="mb-3">BIOML (Bioinformatics, Imaging & Omics using Machine Learning) Lab</h5>
                        <ul>
                            <li>Co-founded a collaborative research group of young researchers from Bangladesh.</li>
                            <li>Focus on ML applications in bioinformatics, biomedical imaging, biomedical signal
                                processing, and omics.</li>
                        </ul>
                        <a href="https://bioml-lab.github.io/" class="btn btn-outline-primary btn-sm" target="_blank"><i
                                class="fas fa-globe me-1"></i>BIOML Homepage</a>
                    </div>
                </div>

                <!-- Grants -->
                <h3 class="text-center mb-4">Research Grants</h3>
                <div class="card mb-5">
                    <div class="card-body">
                        <div class="d-flex justify-content-between">
                            <h4 class="card-title text-primary">Co-Principal Investigator</h4>
                            <span class="badge bg-primary rounded-pill align-self-start">2023 – 2025</span>
                        </div>
                        <h5 class="mb-3">UIU Research Grant, Institute for Advanced Research (IAR)</h5>
                        <ul>
                            <li><strong>Project Title:</strong> “Training Sets vs Training Subsets: Another Method to
                                Reduce Overfitting?”</li>
                            <li><strong>Grant Amount:</strong> BDT 4,90,000</li>
                            <li><strong>Grant ID:</strong> UIU-IAR-02-2022-SE-06</li>
                        </ul>
                        <a href="https://iar.uiu.ac.bd/" class="btn btn-outline-primary btn-sm" target="_blank"><i
                                class="fas fa-globe me-1"></i>IAR Homepage</a>
                    </div>
                </div>

                <!-- Mentorship -->
                <h3 class="text-center mb-4">Mentorship and Supervision</h3>
                <div class="card">
                    <div class="card-body">
                        <p>Supervised or currently supervising 72 students for their undergraduate dissertations,
                            primarily in the fields of Medical Imaging, Bioinformatics, and Health Informatics.</p>
                        <hr>
                        <h5 class="mt-3">Example Supervised Thesis:</h5>
                        <h4 class="card-title text-primary mt-2">Fusion-Based Multimodal Deep Learning to Improve
                            Detection of Diabetic Retinopathy</h4>
                        <p class="card-text">Integrating retinal imaging, clinical data and systemic biomarkers to
                            enhance disease detection.</p>
                        <div class="project-details mt-3">
                            <p class="mb-1"><i class="fas fa-user-tie"></i> Supervisors: Dr. Jannatun Nur Mukta, Md.
                                Saiful Bari Siddiqui</p>
                            <p><i class="fas fa-calendar-alt"></i> January '25 - October '25</p>
                            <a href="https://drive.google.com/file/d/1fDdF3QnpZwDghEyrrO6i9AwlKDweNIAa/view?usp=sharing"
                                class="btn btn-outline-primary btn-sm" target="_blank"><i
                                    class="fas fa-external-link-alt me-1"></i> Thesis Report</a>
                        </div>
                    </div>
                </div>
            </div>
        </section>

        <!-- Connect Section -->
        <section id="connect" class="section fade-in">
            <div class="container">
                <h2>Connect</h2>
                <div class="row">
                    <div class="col-12">
                        <div class="insight-card connect text-center">
                            <h4><i class="fas fa-globe"></i> Get in Touch</h4>
                            <p>Find me on academic and professional networks, or reach out via email.</p>
                            <div class="social-links">
                                <a href="https://github.com/Saiful185" class="btn social-btn github" title="GitHub"
                                    target="_blank" rel="noopener noreferrer"><i class="fab fa-github"></i> GitHub</a>
                                <a href="https://www.linkedin.com/in/md-saiful-bari-siddiqui-8aba351a8/"
                                    class="btn social-btn linkedin" title="LinkedIn" target="_blank"
                                    rel="noopener noreferrer"><i class="fab fa-linkedin"></i> LinkedIn</a>
                                <a href="https://scholar.google.com/citations?user=kSXa-48AAAAJ&hl=en"
                                    class="btn social-btn scholar" title="Google Scholar" target="_blank"
                                    rel="noopener noreferrer"><i class="fas fa-graduation-cap"></i> Google Scholar</a>
                                <a href="https://www.youtube.com/@saifulbariiftu/playlists"
                                    class="btn social-btn youtube" title="YouTube" target="_blank"
                                    rel="noopener noreferrer"><i class="fab fa-youtube"></i> YouTube</a>
                            </div>
                            <div class="contact-info mt-4">
                                <p><i class="fas fa-envelope"></i> <a
                                        href="mailto:saiful.bari@bracu.ac.bd">saiful.bari@bracu.ac.bd</a></p>
                                <p><i class="fas fa-map-marker-alt"></i>North Badda, Dhaka-1212, Bangladesh</p>
                                <p><i class="fas fa-phone"></i> +880-1758805835</p>
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </section>
    </main>

    <!-- Footer -->
    <footer class="text-center">
        <div class="container">
            <p>&copy; 2025 Md. Saiful Bari Siddiqui. All rights reserved.</p>
        </div>
    </footer>

    <!-- JS Scripts (Same as index.html) -->
    <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
    <script>
        const fadeElements = document.querySelectorAll('.fade-in');
        const observer = new IntersectionObserver(entries => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.classList.add('visible');
                }
            });
        });
        fadeElements.forEach(element => {
            observer.observe(element);
        });
    </script>
    <!-- Dark Mode Toggle & Persistence Script -->
    <script>
        const themeToggle = document.getElementById('theme-toggle');
        const body = document.body;
        const icon = themeToggle.querySelector('i');

        // Function to apply the saved theme on page load
        const applyTheme = () => {
            const savedTheme = localStorage.getItem('theme');
            if (savedTheme === 'dark') {
                body.classList.add('dark-mode');
                icon.className = 'fas fa-sun';
            } else {
                body.classList.remove('dark-mode');
                icon.className = 'fas fa-moon';
            }
        };

        // Event listener for the toggle button
        themeToggle.addEventListener('click', () => {
            body.classList.toggle('dark-mode');
            // Save the theme preference to localStorage
            if (body.classList.contains('dark-mode')) {
                localStorage.setItem('theme', 'dark');
                icon.className = 'fas fa-sun';
            } else {
                localStorage.setItem('theme', 'light');
                icon.className = 'fas fa-moon';
            }
        });

        // Apply the theme when the DOM is fully loaded
        document.addEventListener('DOMContentLoaded', applyTheme);
    </script>
</body>

</html>